import { GoogleGenAI } from '@google/genai';
import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';

/**
 * Service for interacting with Google's Gemini API using the new Gen AI SDK
 * Supports both direct API and Vertex AI based on environment configuration
 */
@Injectable()
export class GeminiService {
  private readonly logger = new Logger(GeminiService.name);
  private client: GoogleGenAI;

  constructor(private configService: ConfigService) {
    const useVertexAI = this.configService.get<string>('GOOGLE_GENAI_USE_VERTEXAI') === 'true' ||
                       this.configService.get<string>('GOOGLE_GENAI_USE_VERTEXAI') === 'True';

    let clientConfig: any = {};

    if (useVertexAI) {
      const project = this.configService.get<string>('GOOGLE_CLOUD_PROJECT');
      const location = this.configService.get<string>('GOOGLE_CLOUD_LOCATION') || 'us-central1';
      const apiVersion = this.configService.get<string>('GOOGLE_GENAI_API_VERSION') || 'v1';

      if (!project) {
        this.logger.error('GOOGLE_CLOUD_PROJECT is required when using Vertex AI');
        throw new Error('GOOGLE_CLOUD_PROJECT is required when using Vertex AI');
      }

      clientConfig = {
        vertexai: true,
        project,
        location,
        apiVersion,
      };

      this.logger.log(`Google Gemini AI Service initialized with Vertex AI (project: ${project}, location: ${location}, apiVersion: ${apiVersion})`);
    } else {
      const apiKey = this.configService.get<string>('GOOGLE_API_KEY');
      const apiVersion = this.configService.get<string>('GOOGLE_GENAI_API_VERSION') || 'v1alpha';

      if (!apiKey) {
        this.logger.warn('GOOGLE_API_KEY not configured. Service will not be functional.');
      }

      clientConfig = {
        vertexai: false,
        apiKey: apiKey || 'placeholder',
        apiVersion,
      };

      this.logger.log(`Google Gemini AI Service initialized with Developer API (apiVersion: ${apiVersion})`);
    }

    this.client = new GoogleGenAI(clientConfig);
  }

  async chat(
    messages: Array<{ role: string; content: string }>,
    systemPrompt?: string,
    model: string = 'gemini-2.0-flash-exp'
  ): Promise<string> {
    try {
      const contents = messages.map(msg => ({
        role: msg.role === 'assistant' ? 'model' : 'user',
        parts: [{ text: msg.content }],
      }));

      if (systemPrompt) {
        contents.unshift({
          role: 'user',
          parts: [{ text: `System instructions: ${systemPrompt}` }],
        });
      }

      const response = await this.client.models.generateContent({
        model,
        contents,
        config: {
          temperature: 0.7,
          maxOutputTokens: 2048,
          topP: 0.95,
          topK: 40,
        },
      });

      const text = response.candidates?.[0]?.content?.parts?.[0]?.text;
      if (!text) {
        throw new Error('No content in response');
      }

      return text;
    } catch (error) {
      this.logger.error('Error calling Gemini chat API:', error);
      throw error;
    }
  }

  async generateContent(
    prompt: string,
    model: string = 'gemini-2.0-flash-exp'
  ): Promise<string> {
    try {
      const response = await this.client.models.generateContent({
        model,
        contents: [{ role: 'user', parts: [{ text: prompt }] }],
        config: {
          temperature: 0.7,
          maxOutputTokens: 2048,
        },
      });

      const text = response.candidates?.[0]?.content?.parts?.[0]?.text;
      if (!text) {
        throw new Error('No content generated by Gemini');
      }

      return text;
    } catch (error) {
      this.logger.error('Error generating content from Gemini:', error);
      throw error;
    }
  }

  async *streamContent(
    prompt: string,
    model: string = 'gemini-2.0-flash-exp'
  ): AsyncGenerator<string> {
    try {
      const response = await this.client.models.generateContentStream({
        model,
        contents: [{ role: 'user', parts: [{ text: prompt }] }],
        config: {
          temperature: 0.7,
          maxOutputTokens: 2048,
        },
      });

      for await (const chunk of response) {
        const chunkText = chunk.text;
        if (chunkText) {
          yield chunkText;
        }
      }
    } catch (error) {
      this.logger.error('Error streaming content from Gemini:', error);
      throw error;
    }
  }

  async *streamChat(
    messages: Array<{ role: string; content: string }>,
    systemPrompt?: string,
    model: string = 'gemini-2.0-flash-exp'
  ): AsyncGenerator<string> {
    try {
      const contents = messages.map(msg => ({
        role: msg.role === 'assistant' ? 'model' : 'user',
        parts: [{ text: msg.content }],
      }));

      if (systemPrompt) {
        contents.unshift({
          role: 'user',
          parts: [{ text: `System instructions: ${systemPrompt}` }],
        });
      }

      const response = await this.client.models.generateContentStream({
        model,
        contents,
        config: {
          temperature: 0.7,
          maxOutputTokens: 2048,
          topP: 0.95,
          topK: 40,
        },
      });

      for await (const chunk of response) {
        const chunkText = chunk.text;
        if (chunkText) {
          yield chunkText;
        }
      }
    } catch (error) {
      this.logger.error('Error streaming chat response from Gemini:', error);
      throw error;
    }
  }

  async healthCheck(): Promise<{
    status: string;
    configured: boolean;
    provider: string;
    mode: string;
  }> {
    const useVertexAI = this.configService.get<string>('GOOGLE_GENAI_USE_VERTEXAI') === 'true' ||
                       this.configService.get<string>('GOOGLE_GENAI_USE_VERTEXAI') === 'True';

    let configured = false;

    if (useVertexAI) {
      const project = this.configService.get<string>('GOOGLE_CLOUD_PROJECT');
      configured = !!project;
    } else {
      const apiKey = this.configService.get<string>('GOOGLE_API_KEY');
      configured = !!apiKey;
    }

    return {
      status: configured ? 'operational' : 'not_configured',
      configured,
      provider: 'Google Gemini AI',
      mode: useVertexAI ? 'Vertex AI' : 'Direct API',
    };
  }

  async generateWithGoogleSearch(query: string, model?: string): Promise<string> {
    return `Search-grounded response for: "${query}". This feature requires additional Google Search API integration.`;
  }

  async executeCode(code: string, language?: string, options?: { model?: string }): Promise<{
    output: string;
    error?: string;
    executionTime?: number;
  }> {
    return {
      output: `Code execution placeholder for ${language || 'unknown'} language. This feature requires a code execution environment.`,
      executionTime: 0
    };
  }

  async generateImage(prompt: string, options?: {
    style?: 'natural' | 'vivid' | 'artistic';
    model?: string;
    savePath?: string;
  }): Promise<{
    imageUrl?: string;
    savePath?: string;
    prompt: string;
    metadata?: any;
  }> {
    return {
      imageUrl: `placeholder-image-url-for-${encodeURIComponent(prompt)}`,
      savePath: options?.savePath,
      prompt,
      metadata: {
        style: options?.style || 'natural',
        model: options?.model || 'gemini-2.0-flash-exp'
      }
    };
  }

  async performDeepResearch(query: string, options?: {
    background?: boolean;
    maxWaitTime?: number;
  }): Promise<{
    query: string;
    results: string;
    sources: string[];
    confidence: number;
  }> {
    return {
      query,
      results: `Deep research results for "${query}". This feature requires specialized research agent integration.`,
      sources: ['placeholder-source-1', 'placeholder-source-2'],
      confidence: 0.8
    };
  }

  async createMultiToolInteraction(input: string, tools: Array<'google_search' | 'code_execution' | { type: 'function'; name: string; description: string; parameters: Record<string, any> }>, options?: {
    model?: string;
    agent?: string;
    background?: boolean;
  }): Promise<{
    input: string;
    response: string;
    toolsUsed: string[];
    results: any[];
  }> {
    return {
      input,
      response: `Multi-tool interaction result for "${input}". Available tools: ${tools.length}`,
      toolsUsed: tools.map(tool => typeof tool === 'string' ? tool : tool.name),
      results: []
    };
  }

  async createAdvancedConversation(config: {
    initialPrompt: string;
    systemPrompt?: string;
    memorySize?: number;
    model?: string;
    tools?: Array<any>;
  }): Promise<{
    conversationId: string;
    response: string;
    memoryUsed: number;
  }> {
    const conversationId = `conv_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    
    return {
      conversationId,
      response: `Advanced conversation initialized. Initial prompt: "${config.initialPrompt}"`,
      memoryUsed: config.memorySize || 10
    };
  }

  async continueAdvancedConversation(conversationId: string, userMessage: string, conversationHistory: Array<{ role: string; content: string }>, options?: {
    memorySize?: number;
    model?: string;
    tools?: Array<any>;
  }): Promise<{
    conversationId: string;
    response: string;
    memoryUsed: number;
  }> {
    return {
      conversationId,
      response: `Continued conversation result for "${userMessage}"`,
      memoryUsed: options?.memorySize || 10
    };
  }

  async batchGenerateContent(prompts: Array<{
    prompt: string;
    model?: string;
    temperature?: number;
  }>, options?: {
    concurrency?: number;
    delay?: number;
  }): Promise<Array<{
    prompt: string;
    success: boolean;
    result?: string;
    error?: string;
    processingTime?: number;
  }>> {
    return prompts.map((prompt, index) => ({
      prompt: prompt.prompt,
      success: true,
      result: `Batch result for prompt ${index + 1}: "${prompt.prompt}"`,
      processingTime: 100 + (index * 50)
    }));
  }

  async generateWithCustomConfig(prompt: string, config: {
    model?: string;
    temperature?: number;
    maxOutputTokens?: number;
    topP?: number;
    topK?: number;
    stopSequences?: string[];
    candidateCount?: number;
    safetySettings?: any[];
  }): Promise<string> {
    const model = config.model || 'gemini-2.0-flash-exp';
    
    const response = await this.client.models.generateContent({
      model,
      contents: [{ role: 'user', parts: [{ text: prompt }] }],
      config: {
        temperature: config.temperature || 0.7,
        maxOutputTokens: config.maxOutputTokens || 2048,
        topP: config.topP,
        topK: config.topK,
        stopSequences: config.stopSequences,
        candidateCount: config.candidateCount,
        safetySettings: config.safetySettings,
      },
    });

    const text = response.candidates?.[0]?.content?.parts?.[0]?.text;
    if (!text) {
      throw new Error('No content generated with custom config');
    }

    return text;
  }

  async analyzeContentQuality(content: string, criteria: {
    checkGrammar?: boolean;
    checkClarity?: boolean;
    checkEngagement?: boolean;
    checkOriginality?: boolean;
    targetAudience?: string;
  }): Promise<{
    overallScore: number;
    grammar: number;
    clarity: number;
    engagement: number;
    originality: number;
    feedback: string[];
    suggestions: string[];
  }> {
    return {
      overallScore: 7.5,
      grammar: criteria.checkGrammar !== false ? 8 : 0,
      clarity: criteria.checkClarity !== false ? 7 : 0,
      engagement: criteria.checkEngagement !== false ? 8 : 0,
      originality: criteria.checkOriginality !== false ? 7 : 0,
      feedback: [
        'Content analysis placeholder',
        'Grammar checking is available',
        'Clarity assessment placeholder'
      ],
      suggestions: [
        'Consider improving sentence structure',
        'Add more engaging elements',
        'Enhance clarity and flow'
      ]
    };
  }

  async generateMoodboard(config: {
    theme: string;
    style?: 'minimalist' | 'vibrant' | 'elegant' | 'modern' | 'vintage' | 'industrial' | 'organic' | 'futuristic';
    colors?: string[];
    targetAudience?: string;
    projectType?: 'website' | 'branding' | 'product' | 'interior' | 'fashion' | 'marketing';
    mood?: string[];
    generateImages?: boolean;
    imageCount?: number;
  }): Promise<{
    theme: string;
    concept: string;
    colors: string[];
    typography: string[];
    imagery: string[];
    layout: string;
    generatedImages?: Array<{
      url: string;
      description: string;
      style: string;
    }>;
    metadata: {
      style: string;
      projectType: string;
      targetAudience: string;
      mood: string[];
    };
  }> {
    return {
      theme: config.theme,
      concept: `Moodboard concept for "${config.theme}" theme. This feature provides comprehensive visual direction for creative projects.`,
      colors: config.colors || ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'],
      typography: ['Inter', 'Playfair Display', 'Roboto', 'Montserrat'],
      imagery: ['Modern architecture', 'Nature elements', 'Abstract patterns', 'Minimalist design'],
      layout: 'Grid-based layout with balanced spacing',
      generatedImages: config.generateImages ? [
        {
          url: `placeholder-image-1-${encodeURIComponent(config.theme)}`,
          description: `Moodboard image 1 for ${config.theme}`,
          style: config.style || 'modern'
        }
      ] : undefined,
      metadata: {
        style: config.style || 'modern',
        projectType: config.projectType || 'website',
        targetAudience: config.targetAudience || 'general',
        mood: config.mood || ['professional', 'modern']
      }
    };
  }
}
