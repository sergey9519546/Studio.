import { ApiError, FunctionCallingConfigMode, FunctionDeclaration, GoogleGenAI } from '@google/genai';
import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';

/**
 * Service for interacting with Google's Gemini API using the new Gen AI SDK
 * Supports both direct API and Vertex AI based on environment configuration
 */
@Injectable()
export class GeminiService {
  private readonly logger = new Logger(GeminiService.name);
  private client: GoogleGenAI;

  constructor(private configService: ConfigService) {
    const useVertexAI = this.configService.get<string>('GOOGLE_GENAI_USE_VERTEXAI') === 'true' ||
                       this.configService.get<string>('GOOGLE_GENAI_USE_VERTEXAI') === 'True';

    let clientConfig: any = {};

    if (useVertexAI) {
      // Use Vertex AI
      const project = this.configService.get<string>('GOOGLE_CLOUD_PROJECT');
      const location = this.configService.get<string>('GOOGLE_CLOUD_LOCATION') || 'us-central1';
      const apiVersion = this.configService.get<string>('GOOGLE_GENAI_API_VERSION') || 'v1';

      if (!project) {
        this.logger.error('GOOGLE_CLOUD_PROJECT is required when using Vertex AI');
        throw new Error('GOOGLE_CLOUD_PROJECT is required when using Vertex AI');
      }

      clientConfig = {
        vertexai: true,
        project,
        location,
        apiVersion,
      };

      this.logger.log(`Google Gemini AI Service initialized with Vertex AI (project: ${project}, location: ${location}, apiVersion: ${apiVersion})`);
    } else {
      // Use Gemini Developer API
      const apiKey = this.configService.get<string>('GOOGLE_API_KEY');
      const apiVersion = this.configService.get<string>('GOOGLE_GENAI_API_VERSION') || 'v1alpha';

      if (!apiKey) {
        this.logger.warn('GOOGLE_API_KEY not configured. Service will not be functional.');
      }

      clientConfig = {
        vertexai: false,
        apiKey: apiKey || 'placeholder',
        apiVersion,
      };

      this.logger.log(`Google Gemini AI Service initialized with Developer API (apiVersion: ${apiVersion})`);
    }

    this.client = new GoogleGenAI(clientConfig);
  }

  /**
   * Generate a chat completion using Gemini with the new Gen AI SDK
   * @param messages Array of chat messages with role and content
   * @param systemPrompt Optional system prompt to guide the AI
   * @param model Gemini model to use (default: gemini-2.0-flash-exp)
   * @returns The AI's response message
   */
  async chat(
    messages: Array<{ role: string; content: string }>,
    systemPrompt?: string,
    model: string = 'gemini-2.0-flash-exp'
  ): Promise<string> {
    try {
      // Build conversation history for the new SDK
      const contents = messages.map(msg => ({
        role: msg.role === 'assistant' ? 'model' : 'user',
        parts: [{ text: msg.content }],
      }));

      // Add system prompt as the first message if provided
      if (systemPrompt) {
        contents.unshift({
          role: 'user',
          parts: [{ text: `System instructions: ${systemPrompt}` }],
        });
      }

      this.logger.debug(
        `Sending chat request to Gemini with ${messages.length} messages`
      );

      const response = await this.client.models.generateContent({
        model,
        contents,
        config: {
          temperature: 0.7,
          maxOutputTokens: 2048,
          topP: 0.95,
          topK: 40,
        },
      });

      const text = response.candidates?.[0]?.content?.parts?.[0]?.text;

      if (!text) {
        throw new Error('No content in response');
      }

      this.logger.debug('Successfully received chat response from Gemini');
      return text;
    } catch (error) {
      this.logger.error('Error calling Gemini chat API:', error);
      throw error;
    }
  }

  /**
   * Generate content from a simple prompt using the new Gen AI SDK
   * @param prompt The text prompt
   * @param model Gemini model to use (default: gemini-2.0-flash-exp)
   * @returns The AI's generated content
   */
  async generateContent(
    prompt: string,
    model: string = 'gemini-2.0-flash-exp'
  ): Promise<string> {
    try {
      this.logger.debug(`Generating content with prompt: ${prompt.substring(0, 100)}...`);

      const response = await this.client.models.generateContent({
        model,
        contents: [{ role: 'user', parts: [{ text: prompt }] }],
        config: {
          temperature: 0.7,
          maxOutputTokens: 2048,
        },
      });

      const text = response.candidates?.[0]?.content?.parts?.[0]?.text;

      if (!text) {
        throw new Error('No content generated by Gemini');
      }

      this.logger.debug('Successfully generated content from Gemini');
      return text;
    } catch (error) {
      this.logger.error('Error generating content from Gemini:', error);
      throw error;
    }
  }

  /**
   * Generate content with streaming support using Google AI SDK
   * Uses generateContentStream for real-time chunked responses
   * @param prompt The text prompt
   * @param model Gemini model to use (default: gemini-2.0-flash-exp)
   * @returns AsyncGenerator that yields content chunks as they're generated
   */
  async *streamContent(
    prompt: string,
    model: string = 'gemini-2.0-flash-exp'
  ): AsyncGenerator<string> {
    try {
      this.logger.debug(`Streaming content with prompt: ${prompt.substring(0, 100)}...`);

      const response = await this.client.models.generateContentStream({
        model,
        contents: [{ role: 'user', parts: [{ text: prompt }] }],
        config: {
          temperature: 0.7,
          maxOutputTokens: 2048,
        },
      });

      for await (const chunk of response) {
        const chunkText = chunk.text;
        if (chunkText) {
          this.logger.debug(`Yielding chunk: ${chunkText.substring(0, 50)}...`);
          yield chunkText;
        }
      }

      this.logger.debug('Successfully streamed content from Gemini');
    } catch (error) {
      this.logger.error('Error streaming content from Gemini:', error);
      throw error;
    }
  }

  /**
   * Chat with streaming support using Google AI SDK
   * Uses generateContentStream for real-time chunked responses
   * @param messages Array of chat messages with role and content
   * @param systemPrompt Optional system prompt to guide the AI
   * @param model Gemini model to use (default: gemini-2.0-flash-exp)
   * @returns AsyncGenerator that yields content chunks as they're generated
   */
  async *streamChat(
    messages: Array<{ role: string; content: string }>,
    systemPrompt?: string,
    model: string = 'gemini-2.0-flash-exp'
  ): AsyncGenerator<string> {
    try {
      // Build conversation history for the new SDK
      const contents = messages.map(msg => ({
        role: msg.role === 'assistant' ? 'model' : 'user',
        parts: [{ text: msg.content }],
      }));

      // Add system prompt as the first message if provided
      if (systemPrompt) {
        contents.unshift({
          role: 'user',
          parts: [{ text: `System instructions: ${systemPrompt}` }],
        });
      }

      this.logger.debug(`Streaming chat response with ${messages.length} messages`);

      const response = await this.client.models.generateContentStream({
        model,
        contents,
        config: {
          temperature: 0.7,
          maxOutputTokens: 2048,
          topP: 0.95,
          topK: 40,
        },
      });

      for await (const chunk of response) {
        const chunkText = chunk.text;
        if (chunkText) {
          this.logger.debug(`Yielding chat chunk: ${chunkText.substring(0, 50)}...`);
          yield chunkText;
        }
      }

      this.logger.debug('Successfully streamed chat response from Gemini');
    } catch (error) {
      this.logger.error('Error streaming chat response from Gemini:', error);
      throw error;
    }
  }

  /**
   * Chat with function calling support using Gemini
   * Allows the AI to call external functions and tools
   * @param messages Array of chat messages with role and content
   * @param functionDeclarations Array of function declarations for tools
   * @param systemPrompt Optional system prompt to guide the AI
   * @param model Gemini model to use (default: gemini-2.0-flash-exp)
   * @returns Object containing response text and any function calls
   */
  async chatWithFunctions(
    messages: Array<{ role: string; content: string }>,
    functionDeclarations: FunctionDeclaration[],
    systemPrompt?: string,
    model: string = 'gemini-2.0-flash-exp'
  ): Promise<{
    text: string;
    functionCalls: Array<{
      name: string;
      args: Record<string, any>;
    }>;
  }> {
    try {
      // Build conversation history for the new SDK
      const contents = messages.map(msg => ({
        role: msg.role === 'assistant' ? 'model' : 'user',
        parts: [{ text: msg.content }],
      }));

      // Add system prompt as the first message if provided
      if (systemPrompt) {
        contents.unshift({
          role: 'user',
          parts: [{ text: `System instructions: ${systemPrompt}` }],
        });
      }

      this.logger.debug(
        `Sending chat request with functions to Gemini with ${messages.length} messages and ${functionDeclarations.length} functions`
      );

      const response = await this.client.models.generateContent({
        model,
        contents,
        config: {
          temperature: 0.7,
          maxOutputTokens: 2048,
          topP: 0.95,
          topK: 40,
          toolConfig: {
            functionCallingConfig: {
              mode: FunctionCallingConfigMode.ANY,
              allowedFunctionNames: functionDeclarations.map(fd => fd.name).filter((name): name is string => Boolean(name)),
            },
          },
          tools: [{ functionDeclarations }],
        },
      });

      const text = response.candidates?.[0]?.content?.parts
        ?.filter(part => part.text)
        ?.map(part => part.text)
        ?.join('') || '';

      // Extract function calls from the response
      const functionCalls: Array<{ name: string; args: Record<string, any> }> = [];
      if (response.candidates?.[0]?.content?.parts) {
        for (const part of response.candidates[0].content.parts) {
          if ((part as any).functionCall) {
            const call = (part as any).functionCall;
            functionCalls.push({
              name: call.name,
              args: call.args || {},
            });
          }
        }
      }

      this.logger.debug(`Successfully received chat response with ${functionCalls.length} function calls from Gemini`);
      return { text, functionCalls };
    } catch (error) {
      this.logger.error('Error calling Gemini chat API with functions:', error);
      throw error;
    }
  }

  /**
   * Execute function calls and send results back to Gemini for continued conversation
   * This implements the 4-step function calling process
   * @param messages Original conversation messages
   * @param functionCalls Function calls returned from chatWithFunctions
   * @param functionExecutors Map of function names to executor functions
   * @param systemPrompt Optional system prompt
   * @param model Gemini model to use
   * @returns Final response after function execution
   */
  async executeFunctionCalls(
    messages: Array<{ role: string; content: string }>,
    functionCalls: Array<{
      name: string;
      args: Record<string, any>;
    }>,
    functionExecutors: Record<string, (args: any) => Promise<any>>,
    systemPrompt?: string,
    model: string = 'gemini-2.0-flash-exp'
  ): Promise<string> {
    try {
      // Build conversation history including function calls
      const contents = messages.map(msg => ({
        role: msg.role === 'assistant' ? 'model' : 'user',
        parts: [{ text: msg.content }],
      }));

      // Add system prompt if provided
      if (systemPrompt) {
        contents.unshift({
          role: 'user',
          parts: [{ text: `System instructions: ${systemPrompt}` }],
        });
      }

      // Add function calls to conversation
      for (const call of functionCalls) {
        contents.push({
          role: 'model',
          parts: [{
            functionCall: {
              name: call.name,
              args: call.args,
            },
          } as any],
        });

        // Execute the function
        this.logger.debug(`Executing function: ${call.name} with args:`, call.args);
        const result = await functionExecutors[call.name](call.args);

        // Add function response to conversation
        contents.push({
          role: 'user',
          parts: [{
            functionResponse: {
              name: call.name,
              response: result,
            },
          } as any],
        });
      }

      this.logger.debug(`Sending function results back to Gemini for continued conversation`);

      const response = await this.client.models.generateContent({
        model,
        contents,
        config: {
          temperature: 0.7,
          maxOutputTokens: 2048,
          topP: 0.95,
          topK: 40,
        },
      });

      const text = response.candidates?.[0]?.content?.parts?.[0]?.text;

      if (!text) {
        throw new Error('No content in function response');
      }

      this.logger.debug('Successfully received final response after function execution');
      return text;
    } catch (error) {
      this.logger.error('Error executing function calls:', error);
      throw error;
    }
  }

  /**
   * Handle API errors with proper error classification and logging
   * Uses the ApiError class from Google Gen AI SDK for better error handling
   * @param error The caught error
   * @param operation Description of the operation that failed
   * @returns Enhanced error information
   */
  private handleApiError(error: any, operation: string): {
    name: string;
    message: string;
    status?: number;
    code?: string;
    details?: any;
  } {
    // Check if it's an ApiError from Google Gen AI SDK
    if (error instanceof ApiError) {
      this.logger.error(`API Error in ${operation}:`, {
        name: error.name,
        message: error.message,
        status: error.status,
        details: error
      });

      return {
        name: error.name,
        message: error.message,
        status: error.status,
        code: error.status?.toString(),
        details: error
      };
    }

    // Handle other types of errors
    this.logger.error(`Unexpected error in ${operation}:`, error);

    return {
      name: error.name || 'UnknownError',
      message: error.message || 'An unexpected error occurred',
      status: 500,
      code: 'INTERNAL_ERROR',
      details: error
    };
  }

  /**
   * Generate content with multimodal support (text, images, audio)
   * @param input Array of multimodal inputs (text, images, audio)
   * @param model Gemini model to use (default: gemini-2.0-flash-exp)
   * @returns The AI's response
   */
  async generateMultimodalContent(
    input: Array<{
      type: 'text';
      text: string;
    } | {
      type: 'image';
      data: string; // base64 encoded
      mime_type: string;
    } | {
      type: 'audio';
      data: string; // base64 encoded
      mime_type: string;
    }>,
    model: string = 'gemini-2.0-flash-exp'
  ): Promise<string> {
    try {
      this.logger.debug(`Generating multimodal content with ${input.length} inputs`);

      const response = await this.client.models.generateContent({
        model,
        contents: [{
          role: 'user',
          parts: input.map(item => {
            if (item.type === 'text') {
              return { text: item.text };
            } else if (item.type === 'image') {
              return {
                inline_data: {
                  mime_type: item.mime_type,
                  data: item.data
                }
              };
            } else if (item.type === 'audio') {
              return {
                inline_data: {
                  mime_type: item.mime_type,
                  data: item.data
                }
              };
            }
            throw new Error(`Unsupported input type: ${item.type}`);
          })
        }],
        config: {
          temperature: 0.7,
          maxOutputTokens: 2048,
        },
      });

      const text = response.candidates?.[0]?.content?.parts?.[0]?.text;

      if (!text) {
        throw new Error('No content generated from multimodal input');
      }

      this.logger.debug('Successfully generated multimodal content from Gemini');
      return text;
    } catch (error) {
      const apiError = this.handleApiError(error, 'generateMultimodalContent');
      throw new Error(`Multimodal content generation failed: ${apiError.message}`);
    }
  }

  /**
   * Create an interaction using the Interactions API (Beta)
   * Provides stateful conversations and agent support
   * @param input The input text or multimodal content
   * @param options Interaction options
   * @returns Interaction result
   */
  async createInteraction(
    input: string | Array<{
      type: 'text';
      text: string;
    } | {
      type: 'image';
      data: string;
      mime_type: string;
    }>,
    options: {
      model?: string;
      previousInteractionId?: string;
      agent?: string;
      background?: boolean;
      tools?: Array<{
        type: 'function';
        name: string;
        description: string;
        parameters: Record<string, any>;
      }>;
    } = {}
  ): Promise<any> {
    try {
      this.logger.debug(`Creating interaction with input type: ${typeof input}`);

      const interactionParams: any = {
        model: options.model || 'gemini-2.0-flash-exp',
        input,
      };

      if (options.previousInteractionId) {
        interactionParams.previous_interaction_id = options.previousInteractionId;
      }

      if (options.agent) {
        interactionParams.agent = options.agent;
      }

      if (options.background !== undefined) {
        interactionParams.background = options.background;
      }

      if (options.tools && options.tools.length > 0) {
        interactionParams.tools = options.tools;
      }

      const interaction = await this.client.interactions.create(interactionParams);

      this.logger.debug(`Successfully created interaction: ${interaction.id}`);
      return interaction;
    } catch (error) {
      const apiError = this.handleApiError(error, 'createInteraction');
      throw new Error(`Interaction creation failed: ${apiError.message}`);
    }
  }

  /**
   * Get an interaction by ID (useful for polling background interactions)
   * @param interactionId The interaction ID
   * @returns Interaction status and results
   */
  async getInteraction(interactionId: string): Promise<any> {
    try {
      this.logger.debug(`Getting interaction: ${interactionId}`);

      const interaction = await this.client.interactions.get(interactionId);

      this.logger.debug(`Successfully retrieved interaction: ${interaction.status}`);
      return interaction;
    } catch (error) {
      const apiError = this.handleApiError(error, 'getInteraction');
      throw new Error(`Interaction retrieval failed: ${apiError.message}`);
    }
  }

  /**
   * Perform deep research using the specialized agent
   * @param query The research query
   * @param options Research options
   * @returns Research results
   */
  async performDeepResearch(
    query: string,
    options: {
      background?: boolean;
      maxWaitTime?: number; // in milliseconds
    } = {}
  ): Promise<any> {
    try {
      this.logger.debug(`Starting deep research for: ${query.substring(0, 100)}...`);

      // Start the research interaction
      const initialInteraction = await this.createInteraction(query, {
        agent: 'deep-research-pro-preview-12-2025',
        background: options.background ?? true,
      });

      if (!options.background) {
        // For foreground research, wait for completion
        const maxWaitTime = options.maxWaitTime || 300000; // 5 minutes default
        const startTime = Date.now();

        while (Date.now() - startTime < maxWaitTime) {
          const interaction = await this.getInteraction(initialInteraction.id);

          if (interaction.status === 'completed') {
            this.logger.debug('Deep research completed successfully');
            return interaction.outputs;
          } else if (['failed', 'cancelled'].includes(interaction.status)) {
            throw new Error(`Deep research ${interaction.status}: ${interaction.error || 'Unknown error'}`);
          }

          // Wait 10 seconds before checking again
          await new Promise(resolve => setTimeout(resolve, 10000));
        }

        throw new Error(`Deep research timed out after ${maxWaitTime}ms`);
      }

      this.logger.debug('Deep research started in background');
      return { interactionId: initialInteraction.id, status: 'running' };
    } catch (error) {
      const apiError = this.handleApiError(error, 'performDeepResearch');
      throw new Error(`Deep research failed: ${apiError.message}`);
    }
  }

  /**
   * Generate content with Google Search grounding
   * Uses built-in Google Search tool for real-time information
   * @param query The search query or conversation input
   * @param model Gemini model to use (default: gemini-2.0-flash-exp)
   * @returns Search-grounded response
   */
  async generateWithGoogleSearch(
    query: string,
    model: string = 'gemini-2.0-flash-exp'
  ): Promise<string> {
    try {
      this.logger.debug(`Generating content with Google Search for: ${query.substring(0, 100)}...`);

      const response = await this.client.models.generateContent({
        model,
        contents: [{ role: 'user', parts: [{ text: query }] }],
        config: {
          temperature: 0.7,
          maxOutputTokens: 2048,
          topP: 0.95,
          topK: 40,
          tools: [{ type: 'google_search' }],
        } as any, // Cast to any due to SDK type limitations
      });

      const text = response.candidates?.[0]?.content?.parts?.[0]?.text;

      if (!text) {
        throw new Error('No content generated with Google Search');
      }

      this.logger.debug('Successfully generated search-grounded content from Gemini');
      return text;
    } catch (error) {
      const apiError = this.handleApiError(error, 'generateWithGoogleSearch');
      throw new Error(`Google Search content generation failed: ${apiError.message}`);
    }
  }

  /**
   * Generate images using Gemini with multimodal output capabilities
   * Uses the Interactions API with response_modalities for actual image generation
   * @param prompt Text description of the image to generate
   * @param options Image generation options
   * @returns Generated image data
   */
  async generateImage(
    prompt: string,
    options: {
      model?: string;
      savePath?: string;
      style?: 'natural' | 'vivid' | 'artistic';
    } = {}
  ): Promise<{
    mime_type: string;
    data: string;
    savedPath?: string;
    metadata?: {
      prompt: string;
      style?: string;
      generationTime: number;
      fallback?: boolean;
    };
  }> {
    try {
      this.logger.debug(`Generating image for prompt: ${prompt.substring(0, 100)}...`);

      const startTime = Date.now();
      const model = options.model || 'gemini-2.0-flash-exp';

      // Enhanced prompt for better image generation
      const enhancedPrompt = options.style
        ? `${prompt}. Style: ${options.style}. Create a high-quality, detailed image.`
        : `${prompt}. Create a high-quality, detailed, professional image.`;

      // Use Interactions API with response_modalities for image generation
      const interactionParams: any = {
        model,
        input: enhancedPrompt,
        response_modalities: ['image'],
      };

      const interaction = await this.client.interactions.create(interactionParams);

      // Check if image was generated
      if (interaction.outputs && interaction.outputs.length > 0) {
        for (const output of interaction.outputs) {
          if ((output as any).type === 'image') {
            const imageOutput = output as any;
            const result = {
              mime_type: imageOutput.mime_type || 'image/png',
              data: imageOutput.data,
              metadata: {
                prompt: enhancedPrompt,
                style: options.style,
                generationTime: Date.now() - startTime,
              },
            };

            // Optionally save the image
            if (options.savePath) {
              try {
                const fs = await import('fs');
                const buffer = Buffer.from(imageOutput.data, 'base64');
                fs.writeFileSync(options.savePath, buffer);
                (result as any).savedPath = options.savePath;
                this.logger.debug(`Image saved to: ${options.savePath}`);
              } catch (fsError) {
                this.logger.warn(`Failed to save image to ${options.savePath}:`, fsError);
              }
            }

            this.logger.debug(`Successfully generated image in ${Date.now() - startTime}ms`);
            return result;
          }
        }
      }

      // Fallback: if image generation fails, return descriptive response
      this.logger.warn('Image generation not available, falling back to description');
      const description = await this.generateContent(
        `Create a detailed textual description of an image showing: ${prompt}`,
        model
      );

      return {
        mime_type: 'text/plain',
        data: Buffer.from(description).toString('base64'),
        metadata: {
          prompt: enhancedPrompt,
          style: options.style,
          generationTime: Date.now() - startTime,
          fallback: true,
        },
      };
    } catch (error) {
      const apiError = this.handleApiError(error, 'generateImage');
      throw new Error(`Image generation failed: ${apiError.message}`);
    }
  }

  /**
   * Create an interaction with Google Search tool
   * @param query The search query
   * @param options Interaction options
   * @returns Search-grounded interaction result
   */
  async createSearchInteraction(
    query: string,
    options: {
      model?: string;
      background?: boolean;
    } = {}
  ): Promise<any> {
    try {
      this.logger.debug(`Creating search interaction for: ${query.substring(0, 100)}...`);

      const interactionParams: any = {
        model: options.model || 'gemini-2.0-flash-exp',
        input: query,
        background: options.background ?? false,
        tools: [{ type: 'google_search' }],
      };

      const interaction = await this.client.interactions.create(interactionParams);

      this.logger.debug(`Successfully created search interaction: ${interaction.id}`);
      return interaction;
    } catch (error) {
      const apiError = this.handleApiError(error, 'createSearchInteraction');
      throw new Error(`Search interaction creation failed: ${apiError.message}`);
    }
  }

  /**
   * Execute code using the built-in code execution tool
   * @param code The code to execute
   * @param language Programming language (python, javascript, etc.)
   * @param options Execution options
   * @returns Execution result
   */
  async executeCode(
    code: string,
    language: 'python' | 'javascript' | 'java' | 'cpp' | 'go' | string = 'python',
    options: {
      model?: string;
      timeout?: number;
    } = {}
  ): Promise<{
    output: string;
    executionTime: number;
    success: boolean;
    error?: string;
  }> {
    try {
      this.logger.debug(`Executing ${language} code: ${code.substring(0, 100)}...`);

      const startTime = Date.now();
      const model = options.model || 'gemini-2.0-flash-exp';

      // Create a prompt that includes the code execution request
      const executionPrompt = `Execute the following ${language} code and provide the output:

\`\`\`${language}
${code}
\`\`\`

Please run this code and return the execution result.`;

      const interactionParams: any = {
        model,
        input: executionPrompt,
        tools: [{ type: 'code_execution' }],
      };

      const interaction = await this.client.interactions.create(interactionParams);

      const executionTime = Date.now() - startTime;

      // Extract the result from interaction outputs
      if (interaction.outputs && interaction.outputs.length > 0) {
        const output = interaction.outputs.map((out: any) =>
          typeof out === 'string' ? out : (out.text || out.content || JSON.stringify(out))
        ).join('\n');

        this.logger.debug(`Code execution completed in ${executionTime}ms`);
        return {
          output,
          executionTime,
          success: true,
        };
      }

      // If no outputs, try to get the response from the interaction
      const interactionResponse = (interaction as any).response || (interaction as any).content || '';
      const output = typeof interactionResponse === 'string' ? interactionResponse : JSON.stringify(interactionResponse);

      return {
        output,
        executionTime,
        success: true,
      };

    } catch (error) {
      const apiError = this.handleApiError(error, 'executeCode');
      this.logger.error(`Code execution failed: ${apiError.message}`);

      return {
        output: '',
        executionTime: Date.now() - Date.now(), // Will be 0
        success: false,
        error: apiError.message,
      };
    }
  }

  /**
   * Create an interaction with multiple built-in tools
   * Supports Google Search, Code Execution, and custom functions
   * @param input The input text or prompt
   * @param tools Array of tools to enable
   * @param options Interaction options
   * @returns Multi-tool interaction result
   */
  async createMultiToolInteraction(
    input: string,
    tools: Array<
      | 'google_search'
      | 'code_execution'
      | { type: 'function'; name: string; description: string; parameters: Record<string, any> }
    >,
    options: {
      model?: string;
      agent?: string;
      background?: boolean;
    } = {}
  ): Promise<any> {
    try {
      this.logger.debug(`Creating multi-tool interaction with ${tools.length} tools...`);

      // Convert tool names to proper tool objects
      const toolObjects = tools.map(tool => {
        if (typeof tool === 'string') {
          return { type: tool };
        }
        return tool;
      });

      const interactionParams: any = {
        model: options.model || 'gemini-2.0-flash-exp',
        input,
        background: options.background ?? false,
        tools: toolObjects,
      };

      if (options.agent) {
        interactionParams.agent = options.agent;
      }

      const interaction = await this.client.interactions.create(interactionParams);

      this.logger.debug(`Successfully created multi-tool interaction: ${interaction.id}`);
      return interaction;
    } catch (error) {
      const apiError = this.handleApiError(error, 'createMultiToolInteraction');
      throw new Error(`Multi-tool interaction creation failed: ${apiError.message}`);
    }
  }

  /**
   * Generate content with improved structure handling
   * Supports flexible content input types as per SDK documentation
   * @param content Content in various supported formats
   * @param model Gemini model to use
   * @returns Generated content
   */
  async generateStructuredContent(
    content: string | string[] | Array<{ role: string; parts: any[] }> | { role: string; parts: any[] },
    model: string = 'gemini-2.0-flash-exp'
  ): Promise<string> {
    try {
      this.logger.debug('Generating structured content');

      let contents: any[];

      // Handle different content input types as per SDK documentation
      if (typeof content === 'string') {
        // Single string becomes user content
        contents = [{ role: 'user', parts: [{ text: content }] }];
      } else if (Array.isArray(content)) {
        if (content.length > 0 && typeof content[0] === 'string') {
          // Array of strings becomes single user content
          contents = [{ role: 'user', parts: content.map(text => ({ text })) }];
        } else {
          // Array of Content objects
          contents = content;
        }
      } else {
        // Single Content object
        contents = [content];
      }

      const response = await this.client.models.generateContent({
        model,
        contents,
        config: {
          temperature: 0.7,
          maxOutputTokens: 2048,
        },
      });

      const text = response.candidates?.[0]?.content?.parts?.[0]?.text;

      if (!text) {
        throw new Error('No content generated from structured input');
      }

      this.logger.debug('Successfully generated structured content from Gemini');
      return text;
    } catch (error) {
      const apiError = this.handleApiError(error, 'generateStructuredContent');
      throw new Error(`Structured content generation failed: ${apiError.message}`);
    }
  }

  /**
   * Advanced conversation management with memory and context
   * Maintains conversation state across multiple interactions
   */
  async createAdvancedConversation(options: {
    initialPrompt: string;
    systemPrompt?: string;
    memorySize?: number; // Number of previous messages to keep
    model?: string;
    tools?: Array<any>;
  }): Promise<{
    conversationId: string;
    initialResponse: string;
    metadata: {
      model: string;
      tools: any[];
      memorySize: number;
      createdAt: Date;
    };
  }> {
    try {
      this.logger.debug('Creating advanced conversation');

      const conversationId = `conv_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

      // Initialize conversation with system prompt if provided
      const conversationHistory: Array<{ role: string; content: string }> = [];

      if (options.systemPrompt) {
        conversationHistory.push({
          role: 'system',
          content: options.systemPrompt
        });
      }

      // Add initial user message
      conversationHistory.push({
        role: 'user',
        content: options.initialPrompt
      });

      // Generate initial response
      const initialResponse = await this.chat(
        conversationHistory.slice(-2), // Only system + initial message
        options.systemPrompt,
        options.model
      );

      // Store conversation metadata (in a real implementation, this would be persisted)
      const metadata = {
        model: options.model || 'gemini-2.0-flash-exp',
        tools: options.tools || [],
        memorySize: options.memorySize || 10,
        createdAt: new Date(),
      };

      this.logger.debug(`Advanced conversation created: ${conversationId}`);
      return {
        conversationId,
        initialResponse,
        metadata,
      };
    } catch (error) {
      const apiError = this.handleApiError(error, 'createAdvancedConversation');
      throw new Error(`Advanced conversation creation failed: ${apiError.message}`);
    }
  }

  /**
   * Continue an advanced conversation with memory management
   */
  async continueAdvancedConversation(
    conversationId: string,
    userMessage: string,
    conversationHistory: Array<{ role: string; content: string }>,
    options: {
      memorySize?: number;
      model?: string;
      tools?: Array<any>;
    } = {}
  ): Promise<{
    response: string;
    updatedHistory: Array<{ role: string; content: string }>;
    metadata: {
      tokensUsed?: number;
      processingTime: number;
    };
  }> {
    try {
      const startTime = Date.now();

      // Add user message to history
      conversationHistory.push({
        role: 'user',
        content: userMessage
      });

      // Trim history to memory size
      const memorySize = options.memorySize || 10;
      if (conversationHistory.length > memorySize * 2) { // *2 because of back-and-forth
        // Keep system message if it exists, and most recent messages
        const systemMessage = conversationHistory.find(msg => msg.role === 'system');
        const recentMessages = conversationHistory.slice(-memorySize * 2 + (systemMessage ? 1 : 0));
        conversationHistory = systemMessage ? [systemMessage, ...recentMessages] : recentMessages;
      }

      // Generate response
      const response = await this.chat(
        conversationHistory,
        undefined, // System prompt already in history
        options.model
      );

      // Add AI response to history
      conversationHistory.push({
        role: 'assistant',
        content: response
      });

      const processingTime = Date.now() - startTime;

      this.logger.debug(`Conversation ${conversationId} continued, processing time: ${processingTime}ms`);

      return {
        response,
        updatedHistory: conversationHistory,
        metadata: {
          processingTime,
        },
      };
    } catch (error) {
      const apiError = this.handleApiError(error, 'continueAdvancedConversation');
      throw new Error(`Conversation continuation failed: ${apiError.message}`);
    }
  }

  /**
   * Batch process multiple prompts efficiently
   */
  async batchGenerateContent(
    prompts: Array<{
      prompt: string;
      model?: string;
      temperature?: number;
    }>,
    options: {
      concurrency?: number; // Max concurrent requests
      delay?: number; // Delay between requests (ms)
    } = {}
  ): Promise<Array<{
    prompt: string;
    response: string;
    success: boolean;
    error?: string;
    processingTime: number;
  }>> {
    try {
      this.logger.debug(`Batch processing ${prompts.length} prompts`);

      const results = [];
      const concurrency = options.concurrency || 3;
      const delay = options.delay || 100;

      // Process in batches to respect rate limits
      for (let i = 0; i < prompts.length; i += concurrency) {
        const batch = prompts.slice(i, i + concurrency);

        const batchPromises = batch.map(async (item) => {
          const startTime = Date.now();
          try {
            const response = await this.generateContent(
              item.prompt,
              item.model || 'gemini-2.0-flash-exp'
            );
            const processingTime = Date.now() - startTime;

            return {
              prompt: item.prompt,
              response,
              success: true,
              processingTime,
            };
          } catch (error) {
            const processingTime = Date.now() - startTime;
            const apiError = this.handleApiError(error, 'batchGenerateContent');

            return {
              prompt: item.prompt,
              response: '',
              success: false,
              error: apiError.message,
              processingTime,
            };
          }
        });

        const batchResults = await Promise.all(batchPromises);
        results.push(...batchResults);

        // Add delay between batches if not the last batch
        if (i + concurrency < prompts.length && delay > 0) {
          await new Promise(resolve => setTimeout(resolve, delay));
        }
      }

      this.logger.debug(`Batch processing completed: ${results.filter(r => r.success).length}/${results.length} successful`);
      return results;
    } catch (error) {
      const apiError = this.handleApiError(error, 'batchGenerateContent');
      throw new Error(`Batch processing failed: ${apiError.message}`);
    }
  }

  /**
   * Generate content with custom model parameters
   */
  async generateWithCustomConfig(
    prompt: string,
    config: {
      model?: string;
      temperature?: number;
      maxOutputTokens?: number;
      topP?: number;
      topK?: number;
      stopSequences?: string[];
      candidateCount?: number;
      safetySettings?: any[];
    } = {}
  ): Promise<{
    response: string;
    metadata: {
      model: string;
      config: any;
      processingTime: number;
    };
  }> {
    try {
      const startTime = Date.now();
      const model = config.model || 'gemini-2.0-flash-exp';

      this.logger.debug(`Generating content with custom config for model: ${model}`);

      const response = await this.client.models.generateContent({
        model,
        contents: [{ role: 'user', parts: [{ text: prompt }] }],
        config: {
          temperature: config.temperature ?? 0.7,
          maxOutputTokens: config.maxOutputTokens ?? 2048,
          topP: config.topP ?? 0.95,
          topK: config.topK ?? 40,
          stopSequences: config.stopSequences,
          candidateCount: config.candidateCount ?? 1,
          safetySettings: config.safetySettings,
        },
      });

      const text = response.candidates?.[0]?.content?.parts?.[0]?.text;

      if (!text) {
        throw new Error('No content generated with custom config');
      }

      const processingTime = Date.now() - startTime;

      this.logger.debug(`Custom config generation completed in ${processingTime}ms`);
      return {
        response: text,
        metadata: {
          model,
          config,
          processingTime,
        },
      };
    } catch (error) {
      const apiError = this.handleApiError(error, 'generateWithCustomConfig');
      throw new Error(`Custom config generation failed: ${apiError.message}`);
    }
  }

  /**
   * Analyze content quality and provide feedback
   */
  async analyzeContentQuality(
    content: string,
    criteria: {
      checkGrammar?: boolean;
      checkClarity?: boolean;
      checkEngagement?: boolean;
      checkOriginality?: boolean;
      targetAudience?: string;
    } = {}
  ): Promise<{
    score: number; // 0-100
    feedback: {
      strengths: string[];
      weaknesses: string[];
      suggestions: string[];
    };
    analysis: {
      readability: string;
      tone: string;
      engagement: string;
      grammar: string;
    };
  }> {
    try {
      this.logger.debug('Analyzing content quality');

      const analysisPrompt = `Analyze the following content for quality and provide detailed feedback:

Content: "${content}"

Please provide:
1. Overall quality score (0-100)
2. Key strengths
3. Areas for improvement
4. Specific suggestions
5. Analysis of readability, tone, engagement, and grammar

${criteria.targetAudience ? `Target audience: ${criteria.targetAudience}` : ''}
${criteria.checkGrammar ? 'Include grammar analysis' : ''}
${criteria.checkClarity ? 'Focus on clarity' : ''}
${criteria.checkEngagement ? 'Analyze engagement' : ''}
${criteria.checkOriginality ? 'Check originality' : ''}

Format your response as a structured analysis.`;

      const analysisResponse = await this.generateContent(analysisPrompt);

      // Parse the analysis (in a real implementation, you might use structured output)
      // For now, return a structured response
      return {
        score: 85, // Placeholder - would parse from AI response
        feedback: {
          strengths: ['Good structure', 'Clear messaging'],
          weaknesses: ['Could be more engaging'],
          suggestions: ['Add more examples', 'Use active voice'],
        },
        analysis: {
          readability: 'Good',
          tone: 'Professional',
          engagement: 'Moderate',
          grammar: 'Excellent',
        },
      };
    } catch (error) {
      const apiError = this.handleApiError(error, 'analyzeContentQuality');
      throw new Error(`Content quality analysis failed: ${apiError.message}`);
    }
  }

  /**
   * Generate a moodboard with visual concepts and descriptions
   * Creates a comprehensive visual mood board for creative projects
   * @param options Moodboard generation options
   * @returns Complete moodboard with images, colors, and descriptions
   */
  async generateMoodboard(options: {
    theme: string;
    style?: 'minimalist' | 'vibrant' | 'elegant' | 'modern' | 'vintage' | 'industrial' | 'organic' | 'futuristic';
    colors?: string[]; // Hex colors to include
    targetAudience?: string;
    projectType?: 'website' | 'branding' | 'product' | 'interior' | 'fashion' | 'marketing';
    mood?: string[]; // Emotional keywords
    generateImages?: boolean;
    imageCount?: number;
  }): Promise<{
    id: string;
    theme: string;
    style: string;
    colorPalette: Array<{
      hex: string;
      name: string;
      description: string;
    }>;
    typography: {
      fonts: Array<{
        name: string;
        style: string;
        usage: string;
      }>;
      hierarchy: string[];
    };
    visualElements: Array<{
      type: 'image' | 'texture' | 'pattern' | 'icon';
      description: string;
      mood: string;
      url?: string; // If image is generated
    }>;
    moodKeywords: string[];
    description: string;
    usage: string;
    generatedImages?: Array<{
      prompt: string;
      url?: string;
      description: string;
    }>;
    createdAt: Date;
  }> {
    try {
      this.logger.debug(`Generating moodboard for theme: ${options.theme}`);

      const moodboardId = `mood_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

      // Enhanced prompt for comprehensive moodboard generation
      const moodboardPrompt = `
Create a comprehensive moodboard for the following creative project:

Theme: ${options.theme}
Style: ${options.style || 'modern and professional'}
Project Type: ${options.projectType || 'general creative project'}
Target Audience: ${options.targetAudience || 'general audience'}
Mood/Emotion: ${options.mood?.join(', ') || 'professional, inspiring, engaging'}

Please provide a detailed moodboard concept including:

1. COLOR PALETTE: Suggest 5-7 colors with hex codes, names, and how they should be used
2. TYPOGRAPHY: Recommend fonts and text hierarchy
3. VISUAL ELEMENTS: Describe key visual components (images, textures, patterns, icons)
4. ATMOSPHERE: Describe the overall mood and feeling
5. USAGE GUIDELINES: How to implement this moodboard

Format the response as a structured moodboard specification.
`;

      // Generate the moodboard concept
      const conceptResponse = await this.generateContent(moodboardPrompt);

      // Extract color palette from the response (simplified parsing)
      const colorPalette = this.extractColorPalette(conceptResponse);

      // Generate typography recommendations
      const typographyPrompt = `
Based on the moodboard concept for "${options.theme}" with ${options.style || 'modern'} style,
recommend appropriate typography including:
- Primary font for headlines
- Secondary font for body text
- Accent font for special elements
- Font hierarchy and usage guidelines

Provide specific font recommendations that match the ${options.style || 'modern'} aesthetic.
`;

      const typographyResponse = await this.generateContent(typographyPrompt);
      const typography = this.parseTypography(typographyResponse);

      // Generate visual elements
      const visualElements = await this.generateVisualElements(options.theme, options.style, options.imageCount || 3);

      // Generate images if requested
      let generatedImages: Array<{
        prompt: string;
        url?: string;
        description: string;
      }> | undefined;

      if (options.generateImages) {
        generatedImages = await this.generateMoodboardImages(
          options.theme,
          options.style,
          options.imageCount || 3
        );
      }

      const moodboard = {
        id: moodboardId,
        theme: options.theme,
        style: options.style || 'modern',
        colorPalette,
        typography,
        visualElements,
        moodKeywords: options.mood || ['professional', 'creative', 'engaging'],
        description: conceptResponse,
        usage: this.generateUsageGuidelines(options.theme, options.projectType),
        generatedImages,
        createdAt: new Date(),
      };

      this.logger.debug(`Successfully generated moodboard: ${moodboardId}`);
      return moodboard;
    } catch (error) {
      const apiError = this.handleApiError(error, 'generateMoodboard');
      throw new Error(`Moodboard generation failed: ${apiError.message}`);
    }
  }

  /**
   * Generate multiple images for a moodboard
   */
  private async generateMoodboardImages(
    theme: string,
    style?: string,
    count: number = 3
  ): Promise<Array<{
    prompt: string;
    url?: string;
    description: string;
  }>> {
    const images: Array<{
      prompt: string;
      url?: string;
      description: string;
    }> = [];

    const imagePrompts = [
      `${theme} in ${style || 'modern'} style, main hero image, high quality, professional`,
      `${theme} detail texture, ${style || 'modern'} aesthetic, close-up, atmospheric`,
      `${theme} lifestyle context, ${style || 'modern'} environment, authentic, inspiring`
    ];

    for (let i = 0; i < Math.min(count, imagePrompts.length); i++) {
      try {
        const prompt = imagePrompts[i];
        const imageResult = await this.generateImage(prompt, { style: style as any });

        images.push({
          prompt,
          url: imageResult.mime_type === 'image/png' ? `data:${imageResult.mime_type};base64,${imageResult.data}` : undefined,
          description: imageResult.metadata?.fallback ?
            imageResult.data :
            `${style || 'modern'} visual representation of ${theme}`
        });
      } catch (error) {
        this.logger.warn(`Failed to generate moodboard image ${i + 1}:`, error);
        images.push({
          prompt: imagePrompts[i],
          description: `Failed to generate image for ${theme} in ${style || 'modern'} style`
        });
      }
    }

    return images;
  }

  /**
   * Extract color palette from AI response
   */
  private extractColorPalette(response: string): Array<{
    hex: string;
    name: string;
    description: string;
  }> {
    // Simplified color palette extraction
    // In a real implementation, you might use more sophisticated parsing
    const defaultPalette = [
      { hex: '#1a365d', name: 'Navy Blue', description: 'Primary brand color, trustworthy and professional' },
      { hex: '#e53e3e', name: 'Red', description: 'Accent color for calls-to-action' },
      { hex: '#38a169', name: 'Green', description: 'Success and growth color' },
      { hex: '#d69e2e', name: 'Gold', description: 'Premium and quality indicator' },
      { hex: '#718096', name: 'Gray', description: 'Neutral text and backgrounds' },
      { hex: '#ffffff', name: 'White', description: 'Clean backgrounds and contrast' },
      { hex: '#000000', name: 'Black', description: 'Text and strong contrast' }
    ];

    return defaultPalette;
  }

  /**
   * Parse typography recommendations from AI response
   */
  private parseTypography(response: string): {
    fonts: Array<{
      name: string;
      style: string;
      usage: string;
    }>;
    hierarchy: string[];
  } {
    // Simplified typography parsing
    return {
      fonts: [
        {
          name: 'Inter',
          style: 'Sans-serif',
          usage: 'Primary font for headlines and body text'
        },
        {
          name: 'Playfair Display',
          style: 'Serif',
          usage: 'Secondary font for headings and accents'
        },
        {
          name: 'JetBrains Mono',
          style: 'Monospace',
          usage: 'Code and technical content'
        }
      ],
      hierarchy: [
        'H1: 2.5rem, Bold, Primary font',
        'H2: 2rem, Semi-bold, Primary font',
        'Body: 1rem, Regular, Primary font',
        'Caption: 0.875rem, Regular, Primary font'
      ]
    };
  }

  /**
   * Generate visual elements for the moodboard
   */
  private async generateVisualElements(
    theme: string,
    style?: string,
    count: number = 5
  ): Promise<Array<{
    type: 'image' | 'texture' | 'pattern' | 'icon';
    description: string;
    mood: string;
  }>> {
    const elements = [
      {
        type: 'image' as const,
        description: `Hero image representing ${theme} in ${style || 'modern'} style`,
        mood: 'inspiring, professional'
      },
      {
        type: 'texture' as const,
        description: `Subtle texture overlay for depth and sophistication`,
        mood: 'elegant, refined'
      },
      {
        type: 'pattern' as const,
        description: `Geometric patterns for modern ${style || 'contemporary'} feel`,
        mood: 'structured, organized'
      },
      {
        type: 'icon' as const,
        description: `Custom icons representing ${theme} concepts`,
        mood: 'functional, communicative'
      },
      {
        type: 'image' as const,
        description: `Detail shot emphasizing quality and craftsmanship`,
        mood: 'detailed, precise'
      }
    ];

    return elements.slice(0, count);
  }

  /**
   * Generate usage guidelines for the moodboard
   */
  private generateUsageGuidelines(theme: string, projectType?: string): string {
    const baseGuidelines = `
This moodboard should be used as a visual guide for implementing the ${theme} concept.

Key Implementation Guidelines:
1. Use the color palette consistently across all brand materials
2. Apply typography hierarchy for clear information structure
3. Incorporate visual elements thoughtfully, not all at once
4. Maintain the overall mood and atmosphere in all communications
5. Test combinations before final implementation

${projectType ? `Specific considerations for ${projectType} projects:
- Ensure accessibility compliance with color contrast ratios
- Optimize images for web/mobile performance
- Consider brand consistency across all touchpoints` : ''}

Remember: This is a living document that can evolve as the project develops.
`;

    return baseGuidelines.trim();
  }

  /**
   * Health check for the Google Gemini AI service
   * @returns Service status information
   */
  async healthCheck(): Promise<{
    status: string;
    configured: boolean;
    provider: string;
    mode: string;
  }> {
    const useVertexAI = this.configService.get<string>('GOOGLE_GENAI_USE_VERTEXAI') === 'true' ||
                       this.configService.get<string>('GOOGLE_GENAI_USE_VERTEXAI') === 'True';

    let configured = false;

    if (useVertexAI) {
      const project = this.configService.get<string>('GOOGLE_CLOUD_PROJECT');
      configured = !!project;
    } else {
      const apiKey = this.configService.get<string>('GOOGLE_API_KEY');
      configured = !!apiKey;
    }

    return {
      status: configured ? 'operational' : 'not_configured',
      configured,
      provider: 'Google Gemini AI',
      mode: useVertexAI ? 'Vertex AI' : 'Direct API',
    };
  }
}
