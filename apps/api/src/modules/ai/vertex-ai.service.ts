import { GenerativeModel, GoogleGenerativeAI, HarmBlockThreshold, HarmCategory } from "@google/generative-ai";
import { Injectable, Logger } from "@nestjs/common";
import { ConfigService } from "@nestjs/config";
import type { ToolCall, ToolDefinition } from "./types";

@Injectable()
export class VertexAIService {
  private readonly logger = new Logger(VertexAIService.name);
  private client: GoogleGenerativeAI;
  private readonly project: string;
  private readonly location: string;
  private models: Map<string, GenerativeModel> = new Map();

  constructor(private configService: ConfigService) {
    const apiKey = this.configService.get<string>("GOOGLE_GENAI_API_KEY");
    const projectId = this.configService.get<string>("GCP_PROJECT_ID");

    if (!apiKey) {
      throw new Error("GOOGLE_GENAI_API_KEY is required for Vertex AI");
    }

    if (!projectId) {
      throw new Error("GCP_PROJECT_ID is required for Vertex AI");
    }

    this.project = projectId;
    this.location = this.configService.get<string>("GCP_LOCATION") || "us-central1";

    // Initialize Google Generative AI client
    this.client = new GoogleGenerativeAI(apiKey);

    this.logger.log(
      `Vertex AI initialized: project=${this.project}, location=${this.location}`
    );
  }

  /**
   * Get or create a cached model instance
   */
  private getModel(modelName: string = "gemini-1.5-pro"): GenerativeModel {
    if (!this.models.has(modelName)) {
      const model = this.client.getGenerativeModel({
        model: modelName,
        safetySettings: [
          {
            category: HarmCategory.HARM_CATEGORY_HARASSMENT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
          },
          {
            category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
          },
          {
            category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
          },
          {
            category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
          },
        ],
      });
      this.models.set(modelName, model);
    }
    return this.models.get(modelName)!;
  }

  /**
   * Generate content using Gemini model via Vertex AI
   * 
   * IMPROVEMENT: Added filtering of undefined values in generationConfig
   */
  async generateContent(
    prompt: string,
    model: string = "gemini-1.5-pro",
    options?: { temperature?: number; maxTokens?: number }
  ): Promise<string> {
    try {
      const modelInstance = this.getModel(model);
      
      // Build generation config with filtered undefined values (IMPROVEMENT)
      const generationConfig: Record<string, any> = {};
      if (options?.temperature !== undefined) {
        generationConfig.temperature = options.temperature;
      }
      if (options?.maxTokens !== undefined) {
        generationConfig.maxOutputTokens = options.maxTokens;
      }
      
      const requestConfig = Object.keys(generationConfig).length > 0 ? { generationConfig } : {};

      const result = await modelInstance.generateContent({
        contents: [{ role: 'user', parts: [{ text: prompt }] }],
        ...requestConfig,
      });
      
      const response = await result.response;
      const text = response.text();

      if (!text) {
        throw new Error("No content generated by Vertex AI");
      }

      this.logger.debug(`Generated content with model: ${model}`);
      return text;
    } catch (error) {
      const message =
        error instanceof Error ? error.message : "Unknown Vertex AI error";
      this.logger.error(
        `Vertex AI generation failed: ${message}`,
        error instanceof Error ? error.stack : undefined
      );
      throw error;
    }
  }

  /**
   * Generate content with vision using Gemini model via Vertex AI
   */
  async generateContentWithVision(
    visionPrompt: string,
    imageData: { data: string; mimeType: string },
    model: string = "gemini-1.5-pro"
  ): Promise<string> {
    try {
      const modelInstance = this.getModel(model);

      const imagePart = {
        inlineData: {
          data: imageData.data,
          mimeType: imageData.mimeType,
        },
      };

      const result = await modelInstance.generateContent([visionPrompt, imagePart]);
      const response = await result.response;
      const text = response.text();

      if (!text) {
        throw new Error("No content generated by Vertex AI vision");
      }

      this.logger.debug(`Generated vision content with model: ${model}`);
      return text;
    } catch (error) {
      const message =
        error instanceof Error ? error.message : "Unknown Vertex AI vision error";
      this.logger.error(
        `Vertex AI vision generation failed: ${message}`,
        error instanceof Error ? error.stack : undefined
      );
      throw error;
    }
  }

  /**
   * Generate content with conversation history and optional tools
   * 
   * IMPROVEMENTS:
   * 1. Added explicit model parameter with default
   * 2. Added systemPrompt support via systemInstruction
   */
  async chat(
    messages: Array<{ role: string; content: string }>,
    systemPrompt?: string,
    tools?: ToolDefinition[],
    model: string = "gemini-1.5-pro"  // IMPROVEMENT: Added explicit model parameter
  ): Promise<string | { toolCalls: ToolCall[] }> {
    try {
      const modelInstance = this.getModel(model);  // IMPROVEMENT: Use parameter instead of hardcoded

      // Build startChat configuration
      const chatConfig: Record<string, any> = {
        history: messages.slice(0, -1).map(msg => ({
          role: msg.role === 'assistant' ? 'model' : 'user',
          parts: [{ text: msg.content }],
        })),
        generationConfig: {
          temperature: 0.7,
          maxOutputTokens: 2048,
          topP: 0.95,
          topK: 40,
        },
      };

      // IMPROVEMENT: Add system instruction if systemPrompt is provided
      if (systemPrompt) {
        chatConfig.systemInstruction = {
          parts: [{ text: systemPrompt }]
        };
      }

      // Add tools if provided
      if (tools && tools.length > 0) {
        chatConfig.tools = [{
          functionDeclarations: tools.map(tool => ({
            name: tool.name,
            description: tool.description,
            parameters: tool.parameters,
          })),
        }];
      }

      // Start chat session
      const chat = modelInstance.startChat(chatConfig);

      // Send the last message
      const lastMessage = messages[messages.length - 1];
      const result = await chat.sendMessage(lastMessage.content);
      const response = await result.response;

      // Check for function calls
      const functionCalls = response.functionCalls();
      if (functionCalls && functionCalls.length > 0) {
        const toolCalls: ToolCall[] = functionCalls.map((call: any) => ({
          name: call.name,
          args: call.args,
        }));
        return { toolCalls };
      }

      // Return text response
      const text = response.text();
      if (!text) {
        throw new Error("No response generated by Vertex AI chat");
      }

      this.logger.debug(`Chat completed with ${messages.length} messages`);
      return text;
    } catch (error) {
      const message =
        error instanceof Error ? error.message : "Unknown Vertex AI chat error";
      this.logger.error(
        `Vertex AI chat failed: ${message}`,
        error instanceof Error ? error.stack : undefined
      );
      throw error;
    }
  }

  /**
   * Extract structured data from text using Gemini
   * 
   * IMPROVEMENT: Changed schema parameter type from unknown to object for better type safety
   */
  async extractData(prompt: string, schema?: object): Promise<unknown> {
    let enhancedPrompt = prompt;

    if (schema) {
      enhancedPrompt += `\n\nPlease extract the data and format it as JSON matching this schema:\n${JSON.stringify(schema, null, 2)}`;
    }

    const response = await this.generateContent(enhancedPrompt);

    // Try to parse JSON from response
    try {
      // Look for JSON in markdown code blocks
      const jsonMatch = response.match(
        /```(?:json)?\s*(\{[\s\S]*\}|\[[\s\S]*\])\s*```/
      );
      if (jsonMatch) {
        return JSON.parse(jsonMatch[1]);
      }

      // Try to parse the entire response as JSON
      return JSON.parse(response);
    } catch {
      // If not JSON, return raw response
      return { text: response };
    }
  }

  /**
   * Health check for Vertex AI service
   */
  async healthCheck(): Promise<{
    status: string;
    project: string;
    location: string;
  }> {
    return {
      status: "ok",
      project: this.project,
      location: this.location,
    };
  }
}
